\contentsline {section}{\numberline {1}Introduction}{1}{}%
\contentsline {section}{\numberline {2}Methodology}{2}{}%
\contentsline {subsection}{\numberline {2.1}Environment and MDP Formulation}{2}{}%
\contentsline {subsubsection}{\numberline {2.1.1}State Space (S)}{2}{}%
\contentsline {subsubsection}{\numberline {2.1.2}Action Space (A)}{2}{}%
\contentsline {subsubsection}{\numberline {2.1.3}Reward Function (R)}{3}{}%
\contentsline {subsubsection}{\numberline {2.1.4}Transition Dynamics and Termination}{3}{}%
\contentsline {subsection}{\numberline {2.2}Agent Implementation and Training}{3}{}%
\contentsline {subsubsection}{\numberline {2.2.1}Algorithm Selection and Architecture}{3}{}%
\contentsline {subsubsection}{\numberline {2.2.2}Hyperparameters and Configurations}{3}{}%
\contentsline {subsubsection}{\numberline {2.2.3}Training and Evaluation}{4}{}%
\contentsline {section}{\numberline {3}Results}{4}{}%
\contentsline {subsection}{\numberline {3.1}Standard Evaluation Metrics}{4}{}%
\contentsline {subsection}{\numberline {3.2}Agent Performance Comparison}{4}{}%
\contentsline {subsection}{\numberline {3.3}Final Policy Evaluation}{4}{}%
\contentsline {section}{\numberline {4}Discussion}{4}{}%
\contentsline {subsection}{\numberline {4.1}Learned Optimal Policy}{4}{}%
\contentsline {subsection}{\numberline {4.2}Validation of the Actor-Critic Framework}{4}{}%
\contentsline {subsection}{\numberline {4.3}Limitations and Future Work}{6}{}%
\contentsline {section}{\numberline {5}Conclusion}{7}{}%
